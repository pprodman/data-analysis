{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e207c1db",
   "metadata": {},
   "source": [
    "# Plan de limpieza : de Raw a Processsed\n",
    "\n",
    "Aquí te presento un plan de limpieza completo y estructurado, diseñado para tu proyecto y tu flujo de trabajo (de `raw` a `processed`). Lo dividiremos en:\n",
    "\n",
    "1.  **La Filosofía y el Flujo de Trabajo.**\n",
    "2.  **La Checklist de Limpieza (El \"Qué\" y el \"Cómo\").**\n",
    "3.  **Un Script de Ejemplo (`clean_data.py`) que implementa el plan.**\n",
    "\n",
    "---\n",
    "\n",
    "### 1. La Filosofía y el Flujo de Trabajo\n",
    "\n",
    "**El Principio:** Nunca modifiques tus archivos `raw`. Son tu fuente de verdad inmutable. El proceso de limpieza siempre debe ser: **Leer de `/data/raw/` -> Aplicar Limpieza -> Escribir en `/data/processed/`.**\n",
    "\n",
    "**El Flujo de Trabajo:**\n",
    "\n",
    "1.  **Exploración (en un Notebook de Jupyter):**\n",
    "    *   Carga un archivo de `/data/raw/` en un notebook.\n",
    "    *   Usa métodos como `.info()`, `.describe()`, `.head()`, `.isnull().sum()`, `.value_counts()` para \"entrevistar\" a tus datos y descubrir sus problemas.\n",
    "    *   Prueba diferentes técnicas de limpieza en celdas separadas hasta que encuentres las que funcionan.\n",
    "    *   **El objetivo aquí es DESCUBRIR, no implementar.**\n",
    "\n",
    "2.  **Implementación (en un script `.py`):**\n",
    "    *   Una vez que tienes claras las reglas de limpieza del notebook, las traduces a un script reutilizable (ej. `clean_data.py`).\n",
    "    *   Este script contendrá todas las transformaciones de manera ordenada.\n",
    "    *   **El objetivo aquí es CODIFICAR las reglas de forma reproducible.**\n",
    "\n",
    "---\n",
    "\n",
    "### 2. La Checklist de Limpieza (El \"Qué\" y el \"Cómo\")\n",
    "\n",
    "Vamos a usar tu tabla `organizations` como ejemplo para cada punto.\n",
    "\n",
    "#### ✅ **1. Problemas Estructurales**\n",
    "Son problemas relacionados con la forma y estructura del DataFrame.\n",
    "\n",
    "*   **Nombres de Columnas:**\n",
    "    *   **Qué:** Asegurarse de que los nombres sean consistentes, sin espacios, sin caracteres especiales y en un formato estándar (como `snake_case`, todo en minúsculas y con guiones bajos).\n",
    "    *   **Por qué:** Evita errores al acceder a las columnas y es una práctica estándar en bases de datos.\n",
    "    *   **Cómo:**\n",
    "        ```python\n",
    "        df.columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
    "        ```\n",
    "\n",
    "*   **Eliminar Duplicados:**\n",
    "    *   **Qué:** Buscar y eliminar filas que son copias exactas de otras.\n",
    "    *   **Por qué:** Los duplicados sesgan los análisis (conteos, promedios) y pueden violar restricciones de clave única en la base de datos.\n",
    "    *   **Cómo:**\n",
    "        ```python\n",
    "        print(f\"Filas antes de eliminar duplicados: {len(df)}\")\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print(f\"Filas después de eliminar duplicados: {len(df)}\")\n",
    "        ```\n",
    "\n",
    "*   **Eliminar Columnas Irrelevantes:**\n",
    "    *   **Qué:** Quitar columnas que no aportan valor al análisis (ej. \"columna_vacia\", \"notas_internas\").\n",
    "    *   **Por qué:** Simplifica el DataFrame y reduce el consumo de memoria.\n",
    "    *   **Cómo:**\n",
    "        ```python\n",
    "        df.drop(columns=['columna_inutil_1', 'columna_inutil_2'], inplace=True)\n",
    "        ```\n",
    "\n",
    "#### ✅ **2. Corrección de Tipos de Datos (Casting)**\n",
    "Asegurarse de que cada columna tenga el tipo de dato correcto. Usa `df.info()` para diagnosticar.\n",
    "\n",
    "*   **Columnas Numéricas:**\n",
    "    *   **Qué:** Columnas que deberían ser números (enteros o decimales) pero están como texto (`object`).\n",
    "    *   **Por qué:** Impide operaciones matemáticas.\n",
    "    *   **Cómo:** `pd.to_numeric()` es tu mejor amigo. `errors='coerce'` convierte los valores que no se pueden transformar en `NaN` (nulos).\n",
    "        ```python\n",
    "        df['zip'] = pd.to_numeric(df['zip'], errors='coerce')\n",
    "        df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce')\n",
    "        ```\n",
    "\n",
    "*   **Columnas de Fecha/Hora:** (Aunque no las tengas ahora, es fundamental saberlo)\n",
    "    *   **Qué:** Fechas almacenadas como texto.\n",
    "    *   **Por qué:** Impide análisis de series temporales, cálculos de duración, etc.\n",
    "    *   **Cómo:**\n",
    "        ```python\n",
    "        # df['fecha_creacion'] = pd.to_datetime(df['fecha_creacion'], errors='coerce')\n",
    "        ```\n",
    "\n",
    "#### ✅ **3. Manejo de Valores Nulos (Missing Values)**\n",
    "Decidir qué hacer con las celdas vacías (`NaN`).\n",
    "\n",
    "*   **Estrategia:** La decisión depende del contexto.\n",
    "    *   **Eliminar la fila (`.dropna()`):** Útil si la fila tiene demasiados valores nulos o si un valor nulo en una columna clave (como un ID) la hace inútil.\n",
    "    *   **Rellenar el valor (`.fillna()`):** La opción más común.\n",
    "        *   **Numéricas:** Rellenar con `0`, la media (`df['revenue'].mean()`) o la mediana (`df['revenue'].median()`).\n",
    "        *   **Categóricas/Texto:** Rellenar con una constante como \"Desconocido\" o \"No aplica\".\n",
    "\n",
    "*   **Cómo:**\n",
    "    ```python\n",
    "    # Para revenue, si un nulo significa 0 ingresos, lo rellenamos con 0.\n",
    "    df['revenue'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Para el teléfono, si es nulo, podemos poner un texto indicativo.\n",
    "    df['phone'].fillna('No disponible', inplace=True)\n",
    "    ```\n",
    "\n",
    "#### ✅ **4. Limpieza de Contenido y Formato**\n",
    "Aquí es donde se arregla la \"suciedad\" dentro de las celdas.\n",
    "\n",
    "*   **Eliminar Espacios en Blanco:**\n",
    "    *   **Qué:** Espacios al principio o al final de un texto (ej. `\"  Nombre  \"`).\n",
    "    *   **Por qué:** Causa problemas al agrupar o unir datos. `\"Madrid \"` y `\"Madrid\"` se tratarían como dos ciudades diferentes.\n",
    "    *   **Cómo:** `.str.strip()`\n",
    "        ```python\n",
    "        df['name'] = df['name'].str.strip()\n",
    "        df['city'] = df['city'].str.strip()\n",
    "        ```\n",
    "\n",
    "*   **Estandarizar Mayúsculas/Minúsculas:**\n",
    "    *   **Qué:** Tener \"madrid\", \"Madrid\" y \"MADRID\" en la misma columna.\n",
    "    *   **Por qué:** Mismo problema que los espacios en blanco.\n",
    "    *   **Cómo:** `.str.lower()`, `.str.upper()` o `.str.title()`.\n",
    "        ```python\n",
    "        df['state'] = df['state'].str.upper() # Para códigos de estado como 'CA', 'NY'\n",
    "        df['city'] = df['city'].str.title()   # Para nombres propios como 'Madrid'\n",
    "        ```\n",
    "\n",
    "*   **Limpieza de Texto y Caracteres Especiales (Regex):**\n",
    "    *   **Qué:** Eliminar caracteres no deseados, como guiones o paréntesis en números de teléfono.\n",
    "    *   **Por qué:** Estandariza el formato para su uso posterior.\n",
    "    *   **Cómo:** `.str.replace()` con expresiones regulares (regex).\n",
    "        ```python\n",
    "        # Dejar solo los dígitos en la columna de teléfono\n",
    "        df['phone'] = df['phone'].str.replace(r'\\D', '', regex=True)\n",
    "        ```\n",
    "\n",
    "#### ✅ **5. Validación de Datos y Outliers**\n",
    "El último control de calidad.\n",
    "\n",
    "*   **Rangos de Valores:**\n",
    "    *   **Qué:** Comprobar que los valores numéricos estén dentro de un rango lógico.\n",
    "    *   **Por qué:** Para detectar errores de entrada (ej. un `revenue` negativo, una `utilization` de 5000).\n",
    "    *   **Cómo:** Usar `.describe()` para ver los mínimos y máximos, y luego filtrar.\n",
    "        ```python\n",
    "        # Asegurarse de que la utilización esté entre 0 y 100 (si es un porcentaje)\n",
    "        df = df[(df['utilization'] >= 0) & (df['utilization'] <= 100)]\n",
    "        ```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Script de Ejemplo: `clean_data.py`\n",
    "\n",
    "Este script implementa el plan. Se colocaría en la misma carpeta que tus otros scripts (`/backend/organizations/etl/`).\n",
    "\n",
    "```python\n",
    "# /backend/organizations/etl/clean_data.py\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURACIÓN ---\n",
    "INPUT_DIR = Path('../../data/raw')\n",
    "OUTPUT_DIR = Path('../../data/processed')\n",
    "FILE_NAME = 'organizations_raw.csv' # Asumimos que el raw tiene un nombre diferente\n",
    "OUTPUT_FILE_NAME = 'organizations.csv'\n",
    "\n",
    "def clean_organizations_data():\n",
    "    \"\"\"\n",
    "    Lee datos crudos de organizaciones, los limpia y los guarda en la carpeta 'processed'.\n",
    "    \"\"\"\n",
    "    # --- 1. LECTURA ---\n",
    "    input_path = INPUT_DIR / FILE_NAME\n",
    "    if not input_path.is_file():\n",
    "        print(f\"❌ ERROR: No se encontró el archivo de entrada en {input_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"📄 Leyendo datos desde {input_path}...\")\n",
    "    df = pd.read_csv(input_path, delimiter=';')\n",
    "    print(\"Limpieza iniciada...\")\n",
    "    \n",
    "    # --- 2. LIMPIEZA (Aplicando la checklist) ---\n",
    "\n",
    "    # 2.1. Problemas Estructurales\n",
    "    df.columns = [col.lower() for col in df.columns] # Estandarizar columnas a minúsculas\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 2.2. Corrección de Tipos de Datos\n",
    "    for col in ['zip', 'revenue', 'utilization']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # 2.3. Manejo de Nulos\n",
    "    df['revenue'].fillna(0, inplace=True)\n",
    "    df['utilization'].fillna(0, inplace=True) # Asumimos 0 si no hay dato\n",
    "    df.dropna(subset=['id', 'name'], inplace=True) # Borrar filas si el ID o el nombre son nulos\n",
    "\n",
    "    # 2.4. Limpieza de Contenido\n",
    "    text_cols = ['name', 'address', 'city', 'state', 'phone']\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].str.strip() # Quitar espacios\n",
    "    \n",
    "    df['state'] = df['state'].str.upper() # Estandarizar estado\n",
    "    df['phone'] = df['phone'].str.replace(r'\\D', '', regex=True) # Solo dígitos en teléfono\n",
    "\n",
    "    # 2.5. Validación de Datos\n",
    "    # Mantener solo filas con un ID de longitud válida (ej. 36 para un UUID)\n",
    "    df = df[df['id'].str.len() == 36] \n",
    "    \n",
    "    print(\"✅ Limpieza completada.\")\n",
    "\n",
    "    # --- 3. ESCRITURA ---\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True) # Asegurarse de que el directorio de salida exista\n",
    "    output_path = OUTPUT_DIR / OUTPUT_FILE_NAME\n",
    "    df.to_csv(output_path, index=False, sep=';')\n",
    "    print(f\"💾 Datos limpios guardados en {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clean_organizations_data()\n",
    "```\n",
    "\n",
    "**Tu flujo de trabajo final sería:**\n",
    "1.  Poner el CSV sucio en `/data/raw/organizations_raw.csv`.\n",
    "2.  Ejecutar `python clean_data.py`.\n",
    "3.  Ejecutar `python load_supabase.py` (que ahora leerá el archivo limpio de `/data/processed/organizations.csv`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
